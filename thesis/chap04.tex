\chapter{Application of optimization algorithms}

In this chapter, we describe the problem specific details of our chosen optimization algorithms. Section~\ref{sec:initial_schedules} presents different options for creating initial schedules and explains which ones were chosen for optimization. Section~\ref{sec:coding_of_a_solution} describes the format of non-trivial schedules, which we optimize. \xxx{Section ...}

\section{Initial schedules} \label{sec:initial_schedules}

The creation of initial schedules is part of the simulator's functionality and makes use of \hyperref[para:heuristic_1]{Heuristic 1}.
Each schedule of an intersection consists of two parts: \textit{order} and \textit{times}. Order is an array of street indices that defines the order in which the streets have the green light. Times is an array of integers that defines the duration of the green light with respect to the street order. To keep the two parts consistent, any changes to the order array must also be applied to the corresponding times array.

We provide a few different initialization options for both order and times. Order initializations include:
\begin{itemize}
    \item \textit{default} - simply uses the order given by street IDs in the input file
    \item \textit{random} - takes a random permutation of the streets
    \item \textit{adaptive} - determines the order during a simulation run; whenever a street is used for the first time, it is assigned to the earliest free position in the order array (only usable with the \textit{default} times initialization)
\end{itemize}
Times initializations include:
\begin{itemize}
    \item \textit{default} - all times are set to 1 second
    \item \textit{scaled} - time for each street is a total number of cars using this street divided by a single given constant (the divisor)
\end{itemize}
Both order initialization and times initialization are hyperparameters. To decide which setting to use for optimization, we experimentally compared scores of different initialization options across all datasets.

The results are shown in Figure~\ref{fig:init_comparison}. We can see that by using other ``smarter'' initialization methods, we can significantly improve the baseline solution and start optimizing from much better starting points.
We decided to use \textit{adaptive order} and \textit{default times} for datasets B, C, and D, and \textit{random order} and \textit{scaled times} for datasets E and F (See Table~\ref{tab:hyperparams_datasets_specific}).

\begin{figure}[h]
    \centering
    % \includegraphics[width=.8\linewidth]{img/screenshots/hashcode_datasets_c_e.png}
    \includegraphics[width=\linewidth]{img/experiments/init_experiment.pdf}
    \caption[Comparison of initialization options]{
        Comparison of different initialization options across datasets.
        Specifically, we compare \textcolor{myorange}{\textbf{adaptive}} (adaptive order and default times), \textcolor{mygreen}{\textbf{random}} (random order and default times), and \textcolor{myred}{\textbf{scaled}} (default order and scaled times) options. \textcolor{myblue}{\textbf{Default}} (default order and default times) option represents the baseline solution.
        \textcolor{mygreen}{\textbf{Random}} option is averaged over 100 trials, the black error bars show the 95\% confidence interval.
        For \textcolor{myred}{\textbf{scaled}} option, we use the best divisor between 1--100 for each dataset.
        Y-axis shows the normalized score, where 0 is the baseline score and 1 is the maximum known score for each dataset.
    }
    \label{fig:init_comparison}
\end{figure}

\section{Coding of non-trivial schedules} \label{sec:coding_of_a_solution}

As explained in Section~\ref{sec:further_insights_and_heuristics}, specifically in \hyperref[para:heuristic_2]{Heuristic 2}, we only optimize the non-trivial schedules. The simulator returns the non-trivial schedules in the following format:
\begin{quote}
    a \textbf{list of pairs}, where each pair consists of \textbf{order} and \textbf{times} arrays.
\end{quote}
Analogously, the simulator accepts the non-trivial schedules in the same format when updating them for evaluation.

Since the solution structure is quite complex and each schedule of an intersection can have a different number of streets, we apply the operators for each intersection separately.

\section{Algorithm specifics \xxx{Generating new solutions}}


\section{Genetic algorithm}

\paragraph{Crossover}

For each intersection, we randomly decide whether to crossover only the order, only the times, or both. We use the \textit{order crossover (OX)} for order and the \textit{two-point crossover} for times. The probability of performing crossover is one of the hyperparameters.

\paragraph{Mutation}

For each intersection, we randomly decide whether to mutate only the order, only the times, or both. For order, we use the \textit{index shuffle}, and for times, we add plus or minus one to some values at random. The probability of performing mutation and the probability of mutating each value are tuneable hyperparameters.

\paragraph{Selection}

We use the \textit{tournament selection} with \textit{elitism}. The tournament size and the elitism rate are hyperparameters.

\section{Hill climbing}

As mentioned in Section~\ref{sec:hill_climbing}, we randomly generate the next state because there is no explicit neighborhood structure. To do so, we simply reuse the mutation operator from the genetic algorithm.

\section{Simulated annealing}

We use the same strategy to generate the next state as in hill climbing, i.e., apply the mutation from the genetic algorithm. For the temperature cooling schedule, introduced in Section~\ref{sec:simulated_annealing}, we use a linear decay. It is defined as
\begin{equation}
    schedule(t) = T_0 \cdot \left(1 - \frac{t}{T}\right) + \varepsilon,
\end{equation}
where $T_0$ is the initial temperature, and $T$ is the total number of iterations. Both of these values are hyperparameters, with the initial temperature especially requiring careful tuning for each dataset to achieve good results.
\section{Hyperparameters}

All three aforementioned algorithms depend on the setting of multiple hyperparameters. To find the best hyperparameters for our experiments, we use a \textit{greedy search}. We focus on optimizing one hyperparameter at a time and try to find the best value for it. Other hyperparameters are fixed; either heuristically or to an already optimized value based on the previous runs. We start by tuning more general parameters like the \textit{population size} and gradually move to more specific ones like the \textit{mutation bit rate}. We heuristically try a number of reasonable values for each parameter, e.g., [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] for the mutation probability. We perform runs with additional values if the results are not satisfactory. Every setting is tested on 10 different fixed seeds and the results are averaged.

Most of the hyperparameters were tuned on smaller datasets E and B. However, \xxx{some parameters are highly dependent on the dataset (temperature) and those were also tested on the larger datasets}.

